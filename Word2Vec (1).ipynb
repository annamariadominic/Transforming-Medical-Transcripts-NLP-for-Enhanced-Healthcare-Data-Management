{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#pd.set_option('display.max_colwidth', 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-35-6502e8fc9f2e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-6502e8fc9f2e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    brew install libomp\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "brew install libomp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/opt/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /opt/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-c9e30cedd0e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/lightgbm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from .callback import (early_stopping, print_evaluation, record_evaluation,\n\u001b[1;32m     10\u001b[0m                        reset_parameter)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCFUNCTYPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/opt/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /opt/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "# Basic libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import random\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from itertools import combinations\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import gensim\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# Models\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, make_scorer\n",
    "from lime import lime_text\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A 23-year-old white female presents with comp...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>SUBJECTIVE:,  This 23-year-old white female pr...</td>\n",
       "      <td>allergy / immunology, allergic rhinitis, aller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 2</td>\n",
       "      <td>PAST MEDICAL HISTORY:, He has difficulty climb...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, weigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 1</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , I have seen ABC ...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2-D M-Mode. Doppler.</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 1</td>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d m-mode, dopple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2-D Echocardiogram</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 2</td>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d, doppler, echo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0   A 23-year-old white female presents with comp...   \n",
       "1           1           Consult for laparoscopic gastric bypass.   \n",
       "2           2           Consult for laparoscopic gastric bypass.   \n",
       "3           3                             2-D M-Mode. Doppler.     \n",
       "4           4                                 2-D Echocardiogram   \n",
       "\n",
       "             medical_specialty                                sample_name  \\\n",
       "0         Allergy / Immunology                         Allergic Rhinitis    \n",
       "1                   Bariatrics   Laparoscopic Gastric Bypass Consult - 2    \n",
       "2                   Bariatrics   Laparoscopic Gastric Bypass Consult - 1    \n",
       "3   Cardiovascular / Pulmonary                    2-D Echocardiogram - 1    \n",
       "4   Cardiovascular / Pulmonary                    2-D Echocardiogram - 2    \n",
       "\n",
       "                                       transcription  \\\n",
       "0  SUBJECTIVE:,  This 23-year-old white female pr...   \n",
       "1  PAST MEDICAL HISTORY:, He has difficulty climb...   \n",
       "2  HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n",
       "3  2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4  1.  The left ventricular cavity size and wall ...   \n",
       "\n",
       "                                            keywords  \n",
       "0  allergy / immunology, allergic rhinitis, aller...  \n",
       "1  bariatrics, laparoscopic gastric bypass, weigh...  \n",
       "2  bariatrics, laparoscopic gastric bypass, heart...  \n",
       "3  cardiovascular / pulmonary, 2-d m-mode, dopple...  \n",
       "4  cardiovascular / pulmonary, 2-d, doppler, echo...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"mtsamples.csv\")\n",
    "df = data.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Surgery                          1103\n",
       " Consult - History and Phy.        516\n",
       " Cardiovascular / Pulmonary        372\n",
       " Orthopedic                        355\n",
       " Radiology                         273\n",
       " General Medicine                  259\n",
       " Gastroenterology                  230\n",
       " Neurology                         223\n",
       " SOAP / Chart / Progress Notes     166\n",
       " Obstetrics / Gynecology           160\n",
       " Urology                           158\n",
       " Discharge Summary                 108\n",
       " ENT - Otolaryngology               98\n",
       " Neurosurgery                       94\n",
       " Hematology - Oncology              90\n",
       " Ophthalmology                      83\n",
       " Nephrology                         81\n",
       " Emergency Room Reports             75\n",
       " Pediatrics - Neonatal              70\n",
       " Pain Management                    62\n",
       " Psychiatry / Psychology            53\n",
       " Office Notes                       51\n",
       " Podiatry                           47\n",
       " Dermatology                        29\n",
       " Cosmetic / Plastic Surgery         27\n",
       " Dentistry                          27\n",
       " Letters                            23\n",
       " Physical Medicine - Rehab          21\n",
       " Sleep Medicine                     20\n",
       " Endocrinology                      19\n",
       " Bariatrics                         18\n",
       " IME-QME-Work Comp etc.             16\n",
       " Chiropractic                       14\n",
       " Rheumatology                       10\n",
       " Diets and Nutritions               10\n",
       " Speech - Language                   9\n",
       " Autopsy                             8\n",
       " Lab Medicine - Pathology            8\n",
       " Allergy / Immunology                7\n",
       " Hospice - Palliative Care           6\n",
       "Name: medical_specialty, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.medical_specialty.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.medical_specialty.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping low frequency categories into 'Other'\n",
    "total_samples = len(df)\n",
    "threshold  = 0.02\n",
    "cutoff = threshold * total_samples\n",
    "other_categories = df['medical_specialty'].value_counts()[df['medical_specialty'].value_counts() < cutoff].index\n",
    "df['medical_specialty'] = df['medical_specialty'].replace(other_categories, 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Surgery                          1103\n",
       "Other                             1076\n",
       " Consult - History and Phy.        516\n",
       " Cardiovascular / Pulmonary        372\n",
       " Orthopedic                        355\n",
       " Radiology                         273\n",
       " General Medicine                  259\n",
       " Gastroenterology                  230\n",
       " Neurology                         223\n",
       " SOAP / Chart / Progress Notes     166\n",
       " Obstetrics / Gynecology           160\n",
       " Urology                           158\n",
       " Discharge Summary                 108\n",
       "Name: medical_specialty, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.medical_specialty.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/annadominic/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/annadominic/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35\n",
      "\n",
      "Classification Report:\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "          Allergy / Immunology       0.00      0.00      0.00         2\n",
      "                       Autopsy       0.00      0.00      0.00         1\n",
      "                    Bariatrics       0.00      0.00      0.00         2\n",
      "    Cardiovascular / Pulmonary       0.46      0.14      0.21        79\n",
      "                  Chiropractic       0.00      0.00      0.00         2\n",
      "    Consult - History and Phy.       0.29      0.96      0.44       111\n",
      "    Cosmetic / Plastic Surgery       0.00      0.00      0.00         7\n",
      "                     Dentistry       0.00      0.00      0.00         8\n",
      "                   Dermatology       0.00      0.00      0.00         2\n",
      "          Diets and Nutritions       0.00      0.00      0.00         1\n",
      "             Discharge Summary       0.00      0.00      0.00        23\n",
      "          ENT - Otolaryngology       0.00      0.00      0.00        32\n",
      "        Emergency Room Reports       0.00      0.00      0.00        13\n",
      "                 Endocrinology       0.00      0.00      0.00         2\n",
      "              Gastroenterology       0.00      0.00      0.00        45\n",
      "              General Medicine       0.00      0.00      0.00        44\n",
      "         Hematology - Oncology       0.00      0.00      0.00        19\n",
      "     Hospice - Palliative Care       0.00      0.00      0.00         1\n",
      "        IME-QME-Work Comp etc.       0.00      0.00      0.00         5\n",
      "      Lab Medicine - Pathology       0.00      0.00      0.00         1\n",
      "                       Letters       0.00      0.00      0.00         4\n",
      "                    Nephrology       0.00      0.00      0.00        16\n",
      "                     Neurology       0.12      0.06      0.08        33\n",
      "                  Neurosurgery       0.00      0.00      0.00        20\n",
      "       Obstetrics / Gynecology       0.00      0.00      0.00        23\n",
      "                  Office Notes       0.00      0.00      0.00        11\n",
      "                 Ophthalmology       0.00      0.00      0.00        13\n",
      "                    Orthopedic       0.15      0.03      0.05        62\n",
      "               Pain Management       0.00      0.00      0.00         9\n",
      "         Pediatrics - Neonatal       0.00      0.00      0.00        17\n",
      "     Physical Medicine - Rehab       0.00      0.00      0.00         2\n",
      "                      Podiatry       0.00      0.00      0.00         9\n",
      "       Psychiatry / Psychology       0.00      0.00      0.00        12\n",
      "                     Radiology       0.25      0.02      0.03        64\n",
      " SOAP / Chart / Progress Notes       0.00      0.00      0.00        31\n",
      "                Sleep Medicine       0.00      0.00      0.00         1\n",
      "             Speech - Language       0.00      0.00      0.00         1\n",
      "                       Surgery       0.41      1.00      0.58       230\n",
      "                       Urology       0.00      0.00      0.00        36\n",
      "\n",
      "                      accuracy                           0.35       994\n",
      "                     macro avg       0.04      0.06      0.04       994\n",
      "                  weighted avg       0.19      0.35      0.21       994\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Download NLTK resources\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Custom transformer for lemmatization\n",
    "class Lemmatizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [' '.join([self.lemmatizer.lemmatize(word) for word in document.split()]) for document in X]\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "\n",
    "df.dropna(subset=['transcription'], inplace=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the pipeline with TfidfVectorizer and Multinomial Naive Bayes classifier\n",
    "model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data['transcription'], train_data['medical_specialty'])\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(test_data['transcription'])\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(test_data['medical_specialty'], predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(test_data['medical_specialty'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 3.0563 - accuracy: 0.2468 - val_loss: 2.8332 - val_accuracy: 0.2591\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 2.1800 - accuracy: 0.3620 - val_loss: 2.9561 - val_accuracy: 0.2201\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 1.7636 - accuracy: 0.4183 - val_loss: 3.1279 - val_accuracy: 0.1585\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.5211 - accuracy: 0.4551 - val_loss: 3.4466 - val_accuracy: 0.1472\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 1.3310 - accuracy: 0.4841 - val_loss: 3.6342 - val_accuracy: 0.1107\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.2130 - accuracy: 0.5096 - val_loss: 3.8218 - val_accuracy: 0.1057\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 1.1231 - accuracy: 0.5225 - val_loss: 4.0656 - val_accuracy: 0.0994\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.1055 - accuracy: 0.5257 - val_loss: 4.0615 - val_accuracy: 0.1006\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 1.0580 - accuracy: 0.5307 - val_loss: 4.0561 - val_accuracy: 0.1006\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.0064 - accuracy: 0.5338 - val_loss: 4.3518 - val_accuracy: 0.0918\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2318 - accuracy: 0.1056\n",
      "Test Accuracy: 0.11\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "\n",
      "Classification Report:\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "          Allergy / Immunology       0.00      0.00      0.00         2\n",
      "                       Autopsy       0.00      0.00      0.00         1\n",
      "                    Bariatrics       0.00      0.00      0.00         2\n",
      "    Cardiovascular / Pulmonary       0.11      0.11      0.11        79\n",
      "                  Chiropractic       0.00      0.00      0.00         2\n",
      "    Consult - History and Phy.       0.13      0.14      0.14       111\n",
      "    Cosmetic / Plastic Surgery       0.00      0.00      0.00         7\n",
      "                     Dentistry       0.00      0.00      0.00         8\n",
      "                   Dermatology       0.00      0.00      0.00         2\n",
      "          Diets and Nutritions       0.00      0.00      0.00         1\n",
      "             Discharge Summary       0.10      0.04      0.06        23\n",
      "          ENT - Otolaryngology       0.00      0.00      0.00        32\n",
      "        Emergency Room Reports       0.00      0.00      0.00        13\n",
      "                 Endocrinology       0.00      0.00      0.00         2\n",
      "              Gastroenterology       0.00      0.00      0.00        45\n",
      "              General Medicine       0.02      0.02      0.02        44\n",
      "         Hematology - Oncology       0.00      0.00      0.00        19\n",
      "     Hospice - Palliative Care       0.00      0.00      0.00         1\n",
      "        IME-QME-Work Comp etc.       0.00      0.00      0.00         5\n",
      "      Lab Medicine - Pathology       0.00      0.00      0.00         1\n",
      "                       Letters       0.00      0.00      0.00         4\n",
      "                    Nephrology       0.00      0.00      0.00        16\n",
      "                     Neurology       0.02      0.03      0.03        33\n",
      "                  Neurosurgery       0.00      0.00      0.00        20\n",
      "       Obstetrics / Gynecology       0.00      0.00      0.00        23\n",
      "                  Office Notes       0.00      0.00      0.00        11\n",
      "                 Ophthalmology       0.00      0.00      0.00        13\n",
      "                    Orthopedic       0.04      0.06      0.05        62\n",
      "               Pain Management       0.00      0.00      0.00         9\n",
      "         Pediatrics - Neonatal       0.00      0.00      0.00        17\n",
      "     Physical Medicine - Rehab       0.00      0.00      0.00         2\n",
      "                      Podiatry       0.00      0.00      0.00         9\n",
      "       Psychiatry / Psychology       0.07      0.08      0.08        12\n",
      "                     Radiology       0.17      0.11      0.13        64\n",
      "                  Rheumatology       0.00      0.00      0.00         0\n",
      " SOAP / Chart / Progress Notes       0.04      0.03      0.04        31\n",
      "                Sleep Medicine       0.00      0.00      0.00         1\n",
      "             Speech - Language       0.00      0.00      0.00         1\n",
      "                       Surgery       0.23      0.27      0.25       230\n",
      "                       Urology       0.04      0.03      0.03        36\n",
      "\n",
      "                      accuracy                           0.11       994\n",
      "                     macro avg       0.02      0.02      0.02       994\n",
      "                  weighted avg       0.10      0.11      0.10       994\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Encode the target labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['medical_specialty'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the text\n",
    "max_words = 5000  # Adjust based on your data\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train_data['transcription'])\n",
    "\n",
    "# Convert text to sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data['transcription'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['transcription'])\n",
    "\n",
    "# Pad sequences to ensure consistent length\n",
    "max_sequence_length = 200  # Adjust based on your data\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_sequence_length, padding='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# Load GloVe embeddings (you need to download and provide the path to your GloVe file)\n",
    "embedding_dim = 100  # Adjust based on the GloVe embedding you're using\n",
    "embedding_index = {}\n",
    "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs\n",
    "\n",
    "# Create an embedding matrix\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=max_sequence_length, weights=[embedding_matrix], trainable=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_padded, train_data['label'], epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_padded, test_data['label'])\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_probs = model.predict(test_padded)\n",
    "predictions = predictions_probs.argmax(axis=-1)\n",
    "\n",
    "# Convert predictions back to labels\n",
    "predicted_labels = label_encoder.inverse_transform(predictions)\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(test_data['medical_specialty'], predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preparation\n",
    "\n",
    "def basic_preprocessing(df):\n",
    "    \n",
    "    df_temp = df.copy(deep = True)\n",
    "    \n",
    "    df_temp = df_temp.rename(index = str, columns = {'transcription': 'text'})\n",
    "    \n",
    "    df_temp.loc[:, 'text'] = [text_prepare(x) for x in df_temp['text'].values]\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_temp['medical_specialty'])\n",
    "    df_temp.loc[:, 'class_label'] = le.transform(df_temp['medical_specialty'])\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    df_temp[\"tokens\"] = df_temp[\"text\"].apply(tokenizer.tokenize)\n",
    "    \n",
    "    return df_temp\n",
    "\n",
    "def text_prepare(text):\n",
    "\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = REPLACE_BY_SPACE_RE.sub('', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    words = text.split()\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        if words[i] in STOPWORDS:\n",
    "            words.pop(i)\n",
    "        else:\n",
    "            i += 1\n",
    "    text = ' '.join(map(str, words))# delete stopwords from text\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Introduce evaluation metrics\n",
    "\n",
    "def get_metrics(y_test, y_predicted):  \n",
    "\n",
    "    precision = precision_score(y_test, y_predicted, average='weighted')             \n",
    "\n",
    "    recall = recall_score(y_test, y_predicted, average='weighted')\n",
    "    \n",
    "    f1 = f1_score(y_test, y_predicted, average='weighted')\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BOW(data):\n",
    "    \n",
    "    df_temp = data.copy(deep = True)\n",
    "    df_temp = basic_preprocessing(df_temp)\n",
    "\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    count_vectorizer.fit(df_temp['text'])\n",
    "\n",
    "    list_corpus = df_temp[\"text\"].tolist()\n",
    "    list_labels = df_temp[\"class_label\"].tolist()\n",
    "    \n",
    "    X = count_vectorizer.transform(list_corpus)\n",
    "    \n",
    "    return X, list_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(data, ngrams = 1):\n",
    "\n",
    "    df_temp = data.copy(deep = True)\n",
    "    df_temp = basic_preprocessing(df_temp)\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, ngrams))\n",
    "    tfidf_vectorizer.fit(df_temp['text'])\n",
    "\n",
    "    list_corpus = df_temp[\"text\"].tolist()\n",
    "    list_labels = df_temp[\"class_label\"].tolist()\n",
    "\n",
    "    X = tfidf_vectorizer.transform(list_corpus)\n",
    "    \n",
    "    return X, list_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Download the Google News word vectors (Note: This may take some time)\n",
    "import gensim.downloader as api\n",
    "word_vectors = api.load('word2vec-google-news-300')\n",
    "\n",
    "# Save the word vectors locally (optional)\n",
    "word_vectors.save_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# Load the word vectors from the local file\n",
    "word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# Now you can use 'word2vec' as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word2vec(tokens_list, vector, generate_missing=False, k=300):\n",
    "    if len(tokens_list)<1:\n",
    "        return np.zeros(k)\n",
    "    if generate_missing:\n",
    "        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n",
    "    else:\n",
    "        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
    "    length = len(vectorized)\n",
    "    summed = np.sum(vectorized, axis=0)\n",
    "    averaged = np.divide(summed, length)\n",
    "    return averaged\n",
    "\n",
    "def get_word2vec_embeddings(vectors, clean_questions, generate_missing=False):\n",
    "    embeddings = clean_questions['tokens'].apply(lambda x: get_average_word2vec(x, vectors, \n",
    "                                                                                generate_missing=generate_missing))\n",
    "    return list(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v(data):\n",
    "    \n",
    "    df_temp = data.copy(deep = True)    \n",
    "    df_temp = basic_preprocessing(df_temp)\n",
    "    \n",
    "    embeddings = get_word2vec_embeddings(word2vec, df_temp)\n",
    "    list_labels = df_temp[\"class_label\"].tolist()\n",
    "    \n",
    "    return embeddings, list_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data[data['transcription'].isna()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-22-53cbfe2d7941>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_res = df_res.append({'Preprocessing': 'Bag of words',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-22-53cbfe2d7941>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_res = df_res.append({'Preprocessing': 'TF-IDF 1-gram',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-22-53cbfe2d7941>:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_res = df_res.append({'Preprocessing': 'TF-IDF 2-gram',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-22-53cbfe2d7941>:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_res = df_res.append({'Preprocessing': 'Word2vec',\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "folds = StratifiedKFold(n_splits=3, shuffle=True, random_state = 40)\n",
    "\n",
    "clf = LogisticRegressionCV(cv = folds, solver = 'saga', \n",
    "                           multi_class = 'multinomial', n_jobs = -1, random_state = 40)\n",
    "\n",
    "df_res = pd.DataFrame(columns = ['Preprocessing', 'Precision', 'Recall', 'F1-score', 'Accuracy'])\n",
    "\n",
    "# Bag of words approach\n",
    "X, y = BOW(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)\n",
    "df_res = df_res.append({'Preprocessing': 'Bag of words',\n",
    "                       'Precision': precision,\n",
    "                       'Recall': recall,\n",
    "                       'F1-score': f1,\n",
    "                       'Accuracy': accuracy}, ignore_index = True)\n",
    "\n",
    "# TF_IDF approach. 1-gram\n",
    "X, y = tfidf(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)\n",
    "df_res = df_res.append({'Preprocessing': 'TF-IDF 1-gram',\n",
    "                       'Precision': precision,\n",
    "                       'Recall': recall,\n",
    "                       'F1-score': f1,\n",
    "                       'Accuracy': accuracy}, ignore_index = True)\n",
    "\n",
    "# TF_IDF approach. 2-gram\n",
    "X, y = tfidf(data, ngrams=2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)\n",
    "df_res = df_res.append({'Preprocessing': 'TF-IDF 2-gram',\n",
    "                       'Precision': precision,\n",
    "                       'Recall': recall,\n",
    "                       'F1-score': f1,\n",
    "                       'Accuracy': accuracy}, ignore_index = True)\n",
    "\n",
    "# Word2vec\n",
    "X, y = w2v(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)\n",
    "df_res = df_res.append({'Preprocessing': 'Word2vec',\n",
    "                       'Precision': precision,\n",
    "                       'Recall': recall,\n",
    "                       'F1-score': f1,\n",
    "                       'Accuracy': accuracy}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag of words</td>\n",
       "      <td>0.256824</td>\n",
       "      <td>0.340040</td>\n",
       "      <td>0.258735</td>\n",
       "      <td>0.340040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF-IDF 1-gram</td>\n",
       "      <td>0.204859</td>\n",
       "      <td>0.343058</td>\n",
       "      <td>0.223699</td>\n",
       "      <td>0.343058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TF-IDF 2-gram</td>\n",
       "      <td>0.144673</td>\n",
       "      <td>0.321932</td>\n",
       "      <td>0.179239</td>\n",
       "      <td>0.321932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Word2vec</td>\n",
       "      <td>0.318220</td>\n",
       "      <td>0.378270</td>\n",
       "      <td>0.319280</td>\n",
       "      <td>0.378270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Preprocessing  Precision    Recall  F1-score  Accuracy\n",
       "0   Bag of words   0.256824  0.340040  0.258735  0.340040\n",
       "1  TF-IDF 1-gram   0.204859  0.343058  0.223699  0.343058\n",
       "2  TF-IDF 2-gram   0.144673  0.321932  0.179239  0.321932\n",
       "3       Word2vec   0.318220  0.378270  0.319280  0.378270"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_naive(X_train_naive, X_test_naive, y_train_naive, y_test_naive, preproc):\n",
    "    \n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train_naive, y_train_naive)\n",
    "\n",
    "    res = pd.DataFrame(columns = ['Preprocessing', 'Model', 'Precision', 'Recall', 'F1-score', 'Accuracy'])\n",
    "    \n",
    "    y_pred = clf.predict(X_test_naive)\n",
    "    \n",
    "    f1 = f1_score(y_pred, y_test_naive, average = 'weighted')\n",
    "    pres = precision_score(y_pred, y_test_naive, average = 'weighted')\n",
    "    rec = recall_score(y_pred, y_test_naive, average = 'weighted')\n",
    "    acc = accuracy_score(y_pred, y_test_naive)\n",
    "    \n",
    "    res = res.append({'Preprocessing': preproc, 'Model': 'Naive Bayes', 'Precision': pres, \n",
    "                     'Recall': rec, 'F1-score': f1, 'Accuracy': acc}, ignore_index = True)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_logreg(X_train_log, X_test_log, y_train_log, y_test_log, preproc):\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 40)\n",
    "    \n",
    "    clf = LogisticRegressionCV(cv = folds, solver = 'saga', multi_class = 'multinomial', n_jobs = -1)\n",
    "    \n",
    "    clf.fit(X_train_log, y_train_log)\n",
    "\n",
    "    res = pd.DataFrame(columns = ['Preprocessing', 'Model', 'Precision', 'Recall', 'F1-score', 'Accuracy'])\n",
    "    \n",
    "    y_pred = clf.predict(X_test_log)\n",
    "    \n",
    "    f1 = f1_score(y_pred, y_test_log, average = 'weighted')\n",
    "    pres = precision_score(y_pred, y_test_log, average = 'weighted')\n",
    "    rec = recall_score(y_pred, y_test_log, average = 'weighted')\n",
    "    acc = accuracy_score(y_pred, y_test_log)\n",
    "    \n",
    "    res = res.append({'Preprocessing': preproc, 'Model': f'Logistic Regression', 'Precision': pres, \n",
    "                     'Recall': rec, 'F1-score': f1, 'Accuracy': acc}, ignore_index = True)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from transformers import BertTokenizer, TFBertModel\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "\n",
    "# # Encode the target labels\n",
    "# label_encoder = LabelEncoder()\n",
    "# df['label'] = label_encoder.fit_transform(df['medical_specialty'])\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Load BERT tokenizer and model\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# # Tokenize and pad sequences\n",
    "# train_sequences = tokenizer(list(train_data['transcription']), padding=True, truncation=True, return_tensors='tf')\n",
    "# test_sequences = tokenizer(list(test_data['transcription']), padding=True, truncation=True, return_tensors='tf')\n",
    "\n",
    "# # Get BERT embeddings\n",
    "# train_embeddings = bert_model(train_sequences)['last_hidden_state']\n",
    "# test_embeddings = bert_model(test_sequences)['last_hidden_state']\n",
    "\n",
    "# # Flatten the embeddings\n",
    "# train_embeddings = tf.reduce_mean(train_embeddings, axis=1)\n",
    "# test_embeddings = tf.reduce_mean(test_embeddings, axis=1)\n",
    "\n",
    "# # Build a simple neural network classifier\n",
    "# model = Sequential([\n",
    "#     Dense(128, activation='relu', input_shape=(768,)),\n",
    "#     Dense(len(label_encoder.classes_), activation='softmax')\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(train_embeddings, train_data['label'], epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# # Evaluate the model\n",
    "# test_loss, test_accuracy = model.evaluate(test_embeddings, test_data['label'])\n",
    "# print(f\"Test Accuracy: {test_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/anaconda3/lib/python3.8/site-packages (3.8.3)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.5.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/lib/python3.8/site-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.23.4)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (from smart-open>=1.8.1->gensim) (2.31.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Option 1: Grouping Similar Specialties\n",
    "df['medical_specialty'] = df['medical_specialty'].replace({\n",
    "    'Neurosurgery': 'Neurology',\n",
    "    'Orthopedic': 'Surgery',\n",
    "    # Add more mappings as needed\n",
    "})\n",
    "\n",
    "# Option 2: Combining Low-Frequency Categories\n",
    "# Assuming you want to combine categories with frequencies below a threshold (e.g., 10)\n",
    "threshold = 20\n",
    "low_frequency_categories = df['medical_specialty'].value_counts()[df['medical_specialty'].value_counts() < threshold].index\n",
    "df['medical_specialty'] = df['medical_specialty'].replace(low_frequency_categories, 'Other')\n",
    "\n",
    "# Option 3: Creating Broader Categories\n",
    "df['medical_specialty'] = df['medical_specialty'].replace({\n",
    "    'Cardiovascular / Pulmonary': 'Internal Medicine',\n",
    "    'Gastroenterology': 'Internal Medicine',\n",
    "    # Add more mappings as needed\n",
    "})\n",
    "\n",
    "# Option 4: Specialty Type vs. Subspecialty\n",
    "df['medical_specialty'] = df['medical_specialty'].replace({\n",
    "    'ENT - Otolaryngology': 'Surgery',\n",
    "    'Physical Medicine - Rehab': 'Orthopedic',\n",
    "    'Cosmetic / Plastic Surgery': 'Dermatology',\n",
    "    # Add more mappings as needed\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Surgery                          1103\n",
       " Consult - History and Phy.        516\n",
       " Cardiovascular / Pulmonary        372\n",
       " Orthopedic                        355\n",
       " Radiology                         273\n",
       " General Medicine                  259\n",
       " Gastroenterology                  230\n",
       " Neurology                         223\n",
       " SOAP / Chart / Progress Notes     166\n",
       " Obstetrics / Gynecology           160\n",
       " Urology                           158\n",
       "Other                              125\n",
       " Discharge Summary                 108\n",
       " ENT - Otolaryngology               98\n",
       " Neurosurgery                       94\n",
       " Hematology - Oncology              90\n",
       " Ophthalmology                      83\n",
       " Nephrology                         81\n",
       " Emergency Room Reports             75\n",
       " Pediatrics - Neonatal              70\n",
       " Pain Management                    62\n",
       " Psychiatry / Psychology            53\n",
       " Office Notes                       51\n",
       " Podiatry                           47\n",
       " Dermatology                        29\n",
       " Cosmetic / Plastic Surgery         27\n",
       " Dentistry                          27\n",
       " Letters                            23\n",
       " Physical Medicine - Rehab          21\n",
       " Sleep Medicine                     20\n",
       "Name: medical_specialty, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.medical_specialty.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
